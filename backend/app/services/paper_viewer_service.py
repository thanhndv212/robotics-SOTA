#!/usr/bin/env python3
"""
Paper Viewer Service
====================

Service for parsing and managing paper data from markdown files.
Migrated from SysID-for-robot-learning-papers project.
"""

import os
import re
import json
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Set, Optional


@dataclass
class Paper:
    """Data class to hold paper information"""
    id: str
    title: str
    authors: List[str]
    venue: str
    year: Optional[int]
    category: str
    summary: str
    abstract: str
    contributions: List[str]
    methods: str
    applications: str
    tags: List[str]
    code: str
    dataset: str
    url: str
    doi: str


class MarkdownParser:
    """Parser for markdown files generated by paper_extractor.py"""

    def __init__(self):
        self.papers = []
        self.categories = {}
        self.tags = set()
        self.stats = {}

    def parse_markdown_file(self, filepath: Path) -> bool:
        """Parse markdown file and extract paper information"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"Error reading file: {e}")
            return False

        # Extract statistics
        self._extract_statistics(content)

        # Split into sections by category
        category_sections = re.split(r'\n### ([^(]+) \(\d+ papers\)\n', content)

        if len(category_sections) < 2:
            print("No categories found in markdown file")
            return False

        # Process each category
        for i in range(1, len(category_sections), 2):
            category_name = category_sections[i].strip()
            category_content = category_sections[i + 1] if i + 1 < len(category_sections) else ""

            papers_in_category = self._parse_category_papers(
                category_content, category_name
            )

            self.categories[category_name] = papers_in_category
            self.papers.extend(papers_in_category)

        # Extract all unique tags
        for paper in self.papers:
            self.tags.update(paper.tags)

        print(f"Parsed {len(self.papers)} papers across {len(self.categories)} categories")
        return True

    def _extract_statistics(self, content: str):
        """Extract statistical overview from markdown"""
        stats_match = re.search(
            r'## Statistical Overview\n\n(.*?)\n\n## Papers by Category',
            content,
            re.DOTALL
        )

        if stats_match:
            stats_content = stats_match.group(1)
            for line in stats_content.split('\n'):
                if line.strip().startswith('- **'):
                    match = re.match(r'- \*\*([^*]+)\*\*: (\d+) papers', line)
                    if match:
                        category, count = match.groups()
                        self.stats[category] = int(count)

    def _parse_category_papers(self, content: str, category: str) -> List[Paper]:
        """Parse papers from category content"""
        papers = []

        # Split by paper entries
        paper_sections = re.split(r'\n#### \d+\. ', content)

        for section in paper_sections[1:]:  # Skip first empty section
            paper = self._parse_single_paper(section, category)
            if paper:
                papers.append(paper)

        return papers

    def _parse_single_paper(self, content: str, category: str) -> Optional[Paper]:
        """Parse a single paper from its markdown section"""
        lines = content.strip().split('\n')
        if not lines:
            return None

        # Extract title and URL from first line
        first_line = lines[0]
        title_match = re.match(r'\[([^\]]+)\]\(([^)]*)\)', first_line)

        if not title_match:
            return None

        title = title_match.group(1)
        url = title_match.group(2) if title_match.group(2) != '#' else ''

        # Initialize fields
        authors = []
        venue = "Unknown"
        year = None
        summary = ""
        abstract = ""
        contributions = []
        methods = ""
        applications = ""
        tags = []
        code = "N/A"
        dataset = "N/A"
        doi = ""

        # Parse content line by line
        current_section = None
        for line in lines[1:]:
            line = line.strip()
            if not line or line == '---':
                continue

            # Check for section headers
            if line.startswith('**Authors**:'):
                authors_str = line.replace('**Authors**:', '').strip()
                authors = [a.strip() for a in authors_str.split(',') if a.strip()]
            elif line.startswith('**Venue**:'):
                venue_year = line.replace('**Venue**:', '').strip()
                venue_parts = venue_year.rsplit(',', 1) if ',' in venue_year else [venue_year]
                venue = venue_parts[0].strip()
                if len(venue_parts) > 1:
                    try:
                        year = int(venue_parts[1].strip())
                    except ValueError:
                        pass
            elif line.startswith('**Category**:'):
                pass  # Already have category
            elif line.startswith('**Summary**:'):
                summary = line.replace('**Summary**:', '').strip()
            elif line.startswith('**Abstract**:'):
                abstract = line.replace('**Abstract**:', '').strip()
            elif line.startswith('**Contributions**:'):
                contributions_str = line.replace('**Contributions**:', '').strip()
                contributions = [c.strip('- ').strip() for c in contributions_str.split('\n') if c.strip()]
            elif line.startswith('**Methods**:'):
                methods = line.replace('**Methods**:', '').strip()
            elif line.startswith('**Applications**:'):
                applications = line.replace('**Applications**:', '').strip()
            elif line.startswith('**Tags**:'):
                tags_str = line.replace('**Tags**:', '').strip()
                tags = [t.strip() for t in tags_str.split(',') if t.strip()]
            elif line.startswith('**Code**:'):
                code = line.replace('**Code**:', '').strip()
            elif line.startswith('**Dataset**:'):
                dataset = line.replace('**Dataset**:', '').strip()
            elif line.startswith('**DOI**:'):
                doi = line.replace('**DOI**:', '').strip()

        # Generate ID from title
        paper_id = re.sub(r'[^\w\-_]', '_', title.lower())[:50]

        return Paper(
            id=paper_id,
            title=title,
            authors=authors,
            venue=venue,
            year=year,
            category=category,
            summary=summary,
            abstract=abstract,
            contributions=contributions,
            methods=methods,
            applications=applications,
            tags=tags,
            code=code,
            dataset=dataset,
            url=url,
            doi=doi
        )


class PaperViewerService:
    """Service for managing paper viewer functionality"""

    def __init__(self):
        self.parser = None
        self._load_default_papers()

    def _load_default_papers(self):
        """Load default papers from markdown files"""
        # Look for markdown files in the data directory
        data_dir = Path(__file__).parent.parent.parent.parent / 'data'
        markdown_files = [
            data_dir / 'extracted_papers.md',
            data_dir / 'README.md'
        ]

        for file_path in markdown_files:
            if file_path.exists():
                self.parser = MarkdownParser()
                if self.parser.parse_markdown_file(file_path):
                    print(f"Loaded papers from {file_path}")
                    break
                else:
                    print(f"Failed to parse {file_path}")

        if not self.parser:
            print("Warning: No markdown files found. Paper viewer will be empty.")
            self.parser = MarkdownParser()  # Empty parser

    def reload_papers(self, filepath: Path = None):
        """Reload papers from a specific file or default files"""
        if filepath:
            self.parser = MarkdownParser()
            return self.parser.parse_markdown_file(filepath)
        else:
            self._load_default_papers()
            return True